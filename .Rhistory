knitr::opts_chunk$set(echo = TRUE)
library(MASS)
install.packages("randomForest")
library(randomForest)
train <- sample(1:nrow(Boston),length(Boston$crim),replace = FALSE)
dim(train)
length(train)
data.train <- Boston[train,]
dim(data.train)
dim(Boston)
train
train <- sample(1:nrow(Boston),length(Boston$crim)*0.70,replace = FALSE)
dim(Boston)
data.train <- Boston[train,]
dim(data.train)
data.tes <- Boston[-train,]
data.test <- Boston[-train,]
names(Boston)
head(Boston)
?Boston
names(Boston)
data.train <- Boston[train,-14]
data.test <- Boston[-train,-14]
y.train <- Boston[train,14]
y.test <- Boston[-train,14]
boston.1 <- randomForest(x = data.train,y = y.train,xtest = data.tes,ytest = y.test,
ntree = 500,mtry = ncol(Boston)-1)
y.train
boston.1 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = ncol(Boston)-1)
boston.1
?randomForest()
boston.2 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = (ncol(Boston)-1)/2)
boston.3 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = sqrt(ncol(Boston)-1))
xi <- data.frame(1:500)
xi
xi <- data.frame(arboles = 1:500)
head(xi)
val <- data.frame(arboles = 1:500)
val["MSE1"] <- boston.1$test$mse
val["MSE2"] <- boston.2$test$mse
val["MSE3"] <- boston.3$test$mse
library(ggplot2)
xy <- melt(val,id=c("arboles"))
val
valores <- data.frame(c(1:500))
names(valores) <- "arboles"
valores
xy <- melt(val,id=c("arboles"))
xy <- melt(val,id=c("arboles"))
library(reshape2)
xy <- melt(val,id=c("arboles"))
ggplot(xy)
ggplot(xy)+geom_line(aes(x=arboles,y = valores,color=Variable))
ggplot(xy)+geom_line(aes(x=arboles,y = valores,color=Variable))+
scale_color_manual(names="m =",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))
ggplot(xy)+geom_line(aes(x=arboles,y = valores,color=Variable))+
scale_color_manual(names=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))
ggplot(xy)+geom_line(aes(x=arboles,y = valores,color=Variable))+
scale_color_manual(names=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
dd
xy
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=Variable))+
scale_color_manual(names=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=Variable))+
scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=variable))+
scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","cyan"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=variable))+
scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","green"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
set.seed(0511)
library(MASS)
library(randomForest)
train <- sample(1:nrow(Boston),length(Boston$crim)*0.70,replace = FALSE)
data.train <- Boston[train,-14]
data.test <- Boston[-train,-14]
y.train <- Boston[train,14]
y.test <- Boston[-train,14]
set.seed(0511)
boston.1 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = ncol(Boston)-1)
boston.2 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = (ncol(Boston)-1)/2)
boston.3 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
ntree = 500,mtry = sqrt(ncol(Boston)-1))
val <- data.frame(arboles = 1:500)
val["MSE1"] <- boston.1$test$mse
val["MSE2"] <- boston.2$test$mse
val["MSE3"] <- boston.3$test$mse
library(ggplot2)
library(reshape2)
xy <- melt(val,id=c("arboles"))
theme_set(theme_bw())
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=variable))+
scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","green"))+labs(x = "Número de árboles",
y = "Error de clasificación") +
theme(legend.position="top")
library(ISLR)
set.seed(0511)
?Carseats
train <- sample(1:nrow(Carseats),nrow(Carseats)*0.65,replace = FALSE)
dim(Carseats)
length(train)
set.seed(0511)
train <- sample(1:nrow(Carseats),nrow(Carseats)*0.65,replace = FALSE)
carseats.train <- Carseats[train,]
carseats.test <- Carseats[-train,]
library(tree)
install.packages("tree")
library(tree)
names(Carseats)
tree.carseats <- tree(Sales~.,data = carseats.train)
summary(tree.carseats)
install.packages("rpart")
install.packages("rpart.plot")
library(rpat)
library(rpart)
library(rpart.plot)
rpart.plot(tree.carseats,box.palette = "RdBu",nn=TRUE)
carseats.tree <- rpart(Sales~.,data = carseats.train)
library(rpart)
library(rpart.plot)
carseats.tree <- rpart(Sales~.,data = carseats.train)
rpart.plot(tree.carseats,box.palette = "RdBu",nn=TRUE)
rpart.plot(carseats.tree,box.palette = "RdBu",nn=TRUE)
pred <- predict(carseats.tree,carseats.test)
mean((pred - carseats.test$Sales))
mean((pred - carseats.test$Sales)^2)
printcp(carseats.tree)
plotcp(carseats.tree)
plotcp(carseats.tree)
carseats.tree$cptable
min <- which.min(carseats.tree$cptable[,"xerror"])
prin(min)
print(min)
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"cp"]
carseats.tree$cptable
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"CP"]
cpt
ptree <- prune(carseats.tree,cp = cpt)
rpart.plot(ptree,box.palette = "RdBu",nn=TRUE)
pred1 <- predict(ptree,newdata = carseats.test)
m2 <- mean((pred1-carseats.test$Sales)^2)
m2
bag.carseats <- randomForest(Sales~.,data = carseats.train,mtry= (ncol(Carseats-1)),importance=TRUE)
names(Carseats)
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=sqrt(ncol(Carseats)-1),importance=TRUE)
pred2 <- predict(bag.carseats,newdata = carseats.test)
mean((pred2- carseats.test$Sales)^2)
importance(bag.carseats)
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=ncol(Carseats)-1) ,importance=TRUE)
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=(ncol(Carseats)-1)) ,importance=TRUE)
ncol(Carseats)-1
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=10 ,importance=TRUE)
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=(ncol(Carseats)-1) ,importance=TRUE)
pred2 <- predict(bag.carseats,newdata = carseats.test)
mean((pred2- carseats.test$Sales)^2)
importance(bag.carseats)
bag.carseats <- randomForest(Sales~.,data = carseats.train, mtry=sqrt(ncol(Carseats-1)),importance=TRUE)
bag.carseats <- randomForest(Sales~.,data = carseats.train,mtry=sqrt(ncol(Carseats-1)),importance=TRUE)
bag.carseats <- randomForest(Sales ~ ., data = carseats.train, mtry = sqrt((ncol(Carseats) - 1)), importance = TRUE)
pred.bag <- predict(bag.carseats, newdata = carseats.test)
mean((pred.bag - Carseats.test$Sales)^2)
mean((pred.bag - carseats.test$Sales)^2)
importance(bag.carseats)
O
OJ
train <- sample(x = 1:ncol(OJ),size = ncol(OJ)*0.70,replace = FALSE)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]
OJ.test <- OJ[-train,]
library(tree)
names(OJ)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree)
summary(tree.oj)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)
set.seed(0511)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)
train <- sample(x = 1:ncol(OJ),size = 800,replace = FALSE)
train <- sample(x = 1:ncol(OJ),size = 800)
ncol(OJ)
train <- sample(x = 1:nrow(OJ),size = 800)
OJ.train <- OJ[train,]
set.seed(0511)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)
tree.oj
plot(tree.oj)
text(tree.oj,pretty = 1)
text(tree.oj,pretty = 0)
plot(tree.oj)
text(tree.oj,pretty = 0)
text(tree.oj, pretty = 0)
win.graph()
plot(tree.oj)
text(tree.oj, pretty = 0)
win.graph()
plot(tree.oj)
text(tree.oj, pretty = 0)
plot(tree.oj)
text(tree.oj, pretty = 0)
plot(tree.oj)
text(tree.oj, pretty = 0)
plot(tree.oj)
text(tree.oj, pretty = 0)
win.graph()
plot(tree.oj)
text(tree.oj, pretty = 0)
plot(tree.oj)
text(tree.oj, pretty = 0)
tree.pred <- predict(tree.oj, OJ.test, type = "class")
matriz<-confusionMatrix(tree.pred, OJ.test$Purchase)
tree.pred <- predict(tree.oj, OJ.test, type = "class")
matrix<-confusionMatrix(tree.pred, OJ.test$Purchase)
library(caret)
tree.pred <- predict(tree.oj, OJ.test, type = "class")
matrix<-confusionMatrix(tree.pred, OJ.test$Purchase)
matriz
matrix
cv.oj <- cv.tree(tree.oj,FUN = prune.misclass)
cv.oj
valores <- data.frame(cv.oj$size,cv.oj$dev)
valores <- data.frame(Size=cv.oj$size,Dev=cv.oj$dev)
library(ggplot2)
library(reshape2)
theme_set(theme_bw())
ggplot(data = valores, aes(x=Size, y=Dev)) +
geom_line(color="red", linetype = "dashed") +
geom_point() +
scale_x_discrete(limits=c(1:9))
prune.oj <- prune.misclass(tree.oj,best = 5)
plot(prune.oj)
text(prune.oj,pretty = 0)
plot(prune.oj)
text(prune.oj,pretty = 0)
plot(prune.oj)
text(prune.oj,pretty = 0)
plot(prune.oj)
text(prune.oj,pretty = 0)
plot(prune.oj)
text(prune.oj,pretty = 0)
plot(prune.oj)
text(prune.oj,pretty = 0,digits = 1)
plot(tree.oj)
library(ISLR)
set.seed(0511)
train <- sample(1:nrow(Carseats),nrow(Carseats)*0.65,replace = FALSE)
carseats.train <- Carseats[train,]
carseats.test <- Carseats[-train,]
library(rpart)
library(rpart.plot)
carseats.tree <- rpart(Sales~.,data = carseats.train)
rpart.plot(carseats.tree,box.palette = "RdBu",nn=TRUE)
pred <- predict(carseats.tree,carseats.test)
mean((pred - carseats.test$Sales)^2)
printcp(carseats.tree)
min <- which.min(carseats.tree$cptable[,"xerror"])
print(min)
ptree <- prune(carseats.tree,cp = cpt)
ptree <- prune(carseats.tree,cp = cpt)
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"CP"]
cpt
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"CP"]
cpt
ptree <- prune(carseats.tree,cp = cpt)
rpart.plot(ptree,box.palette = "RdBu",nn=TRUE)
pred1 <- predict(ptree,newdata = carseats.test)
m2 <- mean((pred1-carseats.test$Sales)^2)
m2
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=(ncol(Carseats)-1) ,importance=TRUE)
pred2 <- predict(bag.carseats,newdata = carseats.test)
mean((pred2- carseats.test$Sales)^2)
importance(bag.carseats)
bag.carseats <- randomForest(Sales ~ ., data = carseats.train, mtry = sqrt((ncol(Carseats) - 1)), importance = TRUE)
pred.bag <- predict(bag.carseats, newdata = carseats.test)
mean((pred.bag - carseats.test$Sales)^2)
importance(bag.carseats)
train <- sample(x = 1:nrow(OJ),size = 800)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]
set.seed(0511)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)
tree.oj
plot(tree.oj)
text(tree.oj, pretty = 0)
library(caret)
tree.pred <- predict(tree.oj, OJ.test, type = "class")
matrix<-confusionMatrix(tree.pred, OJ.test$Purchase)
matrix
cv.oj <- cv.tree(tree.oj,FUN = prune.misclass)
cv.oj
library(ggplot2)
library(reshape2)
valores <- data.frame(Size=cv.oj$size,Dev=cv.oj$dev)
theme_set(theme_bw())
ggplot(data = valores, aes(x=Size, y=Dev)) +
geom_line(color="red", linetype = "dashed") +
geom_point() +
scale_x_discrete(limits=c(1:9))
prune.oj <- prune.misclass(tree.oj,best = 5)
plot(prune.oj)
text(prune.oj,pretty = 0,digits = 1)
prune.oj <- prune.misclass(tree.oj,best = 5)
plot(prune.oj)
text(prune.oj,pretty = 0)
summary(prune.oj)
summary(tree.oj)
prune.pred <- predict(prune.oj, OJ.test, type = "class")
matrix<-confusionMatrix(prune.pred, OJ.test$Purchase)
matrix
summary(Hitters)
Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)
train <- 1:200
Hitters.train <- Hitters[train,]
Hitters.test <- Hitters[-train,]
library(gbm)
install.packages("gbm")
set.seed(0511)
p <- seq(-10,-0.2,by=0.1)
lambdas <- 10^p
train.err <- rep(NA,length(lambdas))
lambdas = seq(0.001, 0.3, 0.005)
mse <- rep(0, length(lambdas))
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
pred.train <- predict(boost.hitters, Hitters.train, n.trees = 1000)
mse[i] <- mean((pred.train - Hitters.train$Salary)^2)
}
library(gbm)
library(gbm)
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
pred.train <- predict(boost.hitters, Hitters.train, n.trees = 1000)
mse[i] <- mean((pred.train - Hitters.train$Salary)^2)
}
library(ggplot2)
mse_graph <- data.frame(lambdas)
mse_graph["MSE"]<- mse
names(mse_graph) <- c("Lambdas", "MSE")
theme_set(theme_bw())
ggplot(data = mse_graph, aes(x = Lambdas, y = MSE)) +
geom_line(color="red", linetype = "dashed") +
geom_point()
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
yhat <- predict(boost.hitters, Hitters.test, n.trees = 1000)
mse2[i] <- mean((yhat - Hitters.test$Salary)^2)
}
mse2 <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
yhat <- predict(boost.hitters, Hitters.test, n.trees = 1000)
mse2[i] <- mean((yhat - Hitters.test$Salary)^2)
}
mse2 <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
yhat <- predict(boost.hitters, Hitters.test, n.trees = 1000)
mse2[i] <- mean((yhat - Hitters.test$Salary)^2)
}
library(ggplot2)
mse_graph2 <- data.frame(lambdas)
mse_graph2["MSE"]<- mse2
names(mse_graph2) <- c("Lambdas", "MSE")
theme_set(theme_bw())
ggplot(data = mse_graph2, aes(x = Lambdas, y = MSE)) +
geom_line(color="red", linetype = "dashed") +
geom_point()
min(mse2)
lambdas[which.min(mse2)]
mod8.10 <- lm(Salary~.,data = Hitters.train)
pred8.10 <- predict(mod8.10,Hitters.test)
mod8.10 <- lm(Salary~.,data = Hitters.train)
pred8.10 <- predict(mod8.10,Hitters.test)
mean((pred8.10-Hitters.test)^2)
mean((pred8.10-Hitters.test$Salary)^2)
library(pls)
install.packages("pls")
library(pls)
library(pls)
pcr.fit=pcr(Salary~., data=Hitters.train , scale=TRUE , validation ="CV")
validationplot(pcr.fit ,val.type="MSEP")
pcr.pred=predict (pcr.fit ,Hitters.test,ncomp =1)
mean((pcr.pred -Hitters.test$Salary)^2)
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(mse2)])
summary(boost.hitters)
mean((yhat.bag - Hitters.test$Salary)^2)
bag.hitters <- randomForest(Salary ~ ., data = Hitters.train, mtry = 19)
yhat.bag <- predict(bag.hitters, newdata = Hitters.test)
mean((yhat.bag - Hitters.test$Salary)^2)
