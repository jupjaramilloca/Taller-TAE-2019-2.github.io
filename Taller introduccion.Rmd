---
title: "Desarrollo practico ejercicios TAE  "
author: Est. Estefania Alvarez Piedrahita </center> Est. Juan Pablo Jaramillo Castrillon </br> Universidad Nacional de Colombia - Sede Medellin </br> Escuela De Estadistica.
date: "21 de marzo de 2020"
output: 
  html_document:
    code_folding: hide
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

# Ejercicios {.tabset .tabset-fade .tabset-pills}

## Capitulo IV {.tabset .tabset-fade .tabset-pills}


### Punto 10

*  **Estas pregunta deben respoderse utilizando el conjunto de datos _Weekly_, que es parte del paquete _ISLR_. Estos datos son similares en naturaleza a datos de _Smarket_ de este capítulo, excepto que contiene 1,089 Regresos semanales durante 21 años, desde principios de 1990 hasta el final del 2010.**




**(a) Produzaca algunos resumenes numéricos y gráficos de los datos _Weekly_.¿ parace que hay patrones?.**

>Resumen de variables:

```{r}
library(ISLR)
data("Weekly")
summary(Weekly)


```


>Matriz de gráfico de dispersión:

```{r}
pairs(Weekly)
```

En la primera matriz muestra un resumen de las variables a trabajar, observamos que todas estan a una misma escala, ecepto la varible dirección que cuenta con dos niveles (Alto y bajo). En la segunda matriz las varibles lag1,lag2,lag3,lag4,lag5 y volumen, son variables que entre ellas aparentemente las observaciones se concentrar en el centro; podemos notar que las varible año y variable volume tiene un comportamiento de un polinomio de grado dos acsendente mientras pasa el tiempo.



>Matriz de correlaciones

```{r}
cor(Weekly[,-9])

```

**(b) Utilice el conjunto de datos completo para realizar una regresion logística con _Direction_ como la respuesta y la cinco varibles de retraso mas _Volume_ como predictoras. Use la funcion summary para imprimir los resultados. ¿algunos de los predictores parece ser estadisticamente significativos? si es asi ¿cuales son estas variables? **

> Resumen Regresión logística


```{r}

mod1 <- glm( Direction ~ Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data = Weekly,family = "binomial")
summary(mod1)


```

Podemos observar que la variable Lag2 con un **P-valor** de 0.0296 es estadisiticamente significativa con un nivel de confianza de 0.05.


**(c) Compute la matrix de confusión y la fracción general de las predicciones correctas. Explica qué te dice la matriz de confusión logística.**

>Tabla de confusión

```{r}
prediction <- mod1$fitted.values
pred<- rep("Dow",length(prediction))
pred[prediction > 0.5]<- "Up"
table(pred,Weekly$Direction)

```


Con esta tabla de confusión y los datos de pruba, podemos concluir que el porcentaje de acierto en la prediccion es de $\frac{54+557}{1089} = 0.5610 \times 100$ = 56.10% del tiempo . La tasa de error con los datos de entrenamiento es del 100%-56.10% = 43.8%. Tambien apreciamos que cuando el mercado sube, El modelo acierta $\frac{557}{48+557}=0.92\times100%$=92% de la veces, tambien cuando el mercado baja el modelo acierta un $\frac{54}{54+430}=0.1115\times 100$ = 11.15%  del tiempo.








**(d) Ahora ajuste el modelo de regresión logística utilizando un período de datos de entrenamiento de 1990 a 2008, con Lag2 como el unico predictor. Calcule la matriz de confusión y la fracción general de las predicciones correctas para los datos retenidos (Es decir, los datos de 2009 y 2010)**

>Resumen Modelo con lag2.

```{r}

train <- subset.data.frame(x = Weekly,subset = Year < 2009)
test2009_2010 <- subset.data.frame(Weekly,subset = Year >=2009)
mod2 <- glm(Direction ~ Lag2 ,data = train,family = binomial)
summary(mod2)
```

>Tabla de confusión

```{r}
prediction2 <- predict(object = mod2,newdata = test2009_2010,type = "response")
pred2<- rep("Dow",length(prediction2))
pred2[prediction2 > 0.5]<- "Up"
table(pred2,test2009_2010$Direction)

```

Con esta tabla de confusión y los datos de pruba, podemos concluir que el porcentaje de acierto en la prediccion es de $\frac{9+56}{104}=0.625\times 100$= 62.5%  del tiempo. La tasa de error con los datos de prueba es del 100%-62.5% = 37.5%. Tambien apreciamos que cuando el mercado sube, El modelo acierta $\frac{56}{5+56}=0.9180\times100%$=91.8% del tiempo, tambien cuando el mercado baja el modelo acierta un  $\frac{34}{34+9}=0.79\times 100$ = 79.6% del tiempo.




**(e) Repita (d) usando LDA**

>Resumen modelo LDA:

```{r}
library(MASS)
modlda <- lda(Direction~Lag2,data = train)
modlda
```

>Tabla de confusión:

```{r}
prediction_LDA <- predict(object = modlda,newdata = test2009_2010)
table(prediction_LDA$class,test2009_2010$Direction)
```


Con esta tabla de confusión y los datos de pruba, podemos concluir que el porcentaje de acierto en la prediccion es de $\frac{9+56}{104}=0.625\times 100$= 62.5%  del tiempo. La tasa de error con los datos de prueba es del 100%-62.5% = 37.5%. Tambien apreciamos que cuando el mercado sube, El modelo acierta $\frac{56}{5+56}=0.9180\times100%$=91.8% de la veces, tambien cuando el mercado baja el modelo acierta un  $\frac{34}{34+9}=0.79\times 100$ = 79.6% del tiempo.




**(f) Repita (d) usando QDA**

>Resumen modelo QDA

```{r}
mod_QDA <-  qda(Direction~Lag2,data = train)
mod_QDA
```


```{r}
prediction_QDA <- predict(mod_QDA,newdata = test2009_2010)
table(prediction_QDA$class,test2009_2010$Direction)
```


Con esta tabla de confusión y los datos de pruba, podemos concluir que el porcentaje de acierto en la prediccion es de $\frac{0+61}{104}=0.5865 \times 100$= 58.65%  del tiempo. La tasa de error con los datos de prueba es del 100%-58.65% = 41.35%. Tambien apreciamos que cuando el mercado sube, El modelo acierta $\frac{61}{61}=1$ osea el 100% de la veces, Se resalta este modelo de anialisis de discriminación cudratica elige una dirección alta todo el tiempo.

**(g) Repita (d) usando Knn con k=1.**

>Table de confusión:

```{r}
library(class)
train.x <- as.matrix(train$Lag2)
test.x <- as.matrix(test2009_2010$Lag2)
train.Direction <- train$Direction
set.seed(1)
prediction_knn <- knn(train = train.x,test = test.x,cl = train.Direction,k = 1)
table(prediction_knn,test2009_2010$Direction)
```

Con esta tabla de confusión y los datos de pruba, podemos concluir que el porcentaje de acierto en la prediccion es de 62.5%  del tiempo. La tasa de error con los datos de prueba es del 100%-56.10% = 43.9%. Tambien apreciamos que cuando el mercado sube, El modelo acierta 50.81% de la veces, tambien cuando el mercado baja el modelo acierta un  48.83% del tiempo.


**(h) ¿ cuál de estos métodos parece proporcionar los mejores resultados con estos datos ?**

Con los modelos anteriores, vemos que el _modelo de regresión logístico_ y _LDA_, La tasa de error es mínima. tambien para los modelos _QDA_ y _KNN_ un poco menores.



**(i) Experimente con diferentes combinaciones de predictores, incluyendo posibles transformaciones, para cada uno de los métodos, reporte la variables,método y la matriz de confusión asociada que parece proporcionar los mejores resultados en los mejores resultados en los datos retenidos.Tenga encuenta también debe experimentar con los valores para _K_ en la clasificación con KNN. **

La variable mas significativa es Lag2 como se mostro en los anteriores puntos para tener una interacción con las segunda varible significativa.




```{r}
library(MASS)
library(class)

mod_inter_1 <- glm(Direction~Lag2:Lag1,family = binomial,data = train)
prediction_inter_1 <- predict(mod_inter_1,test2009_2010,type = "response")
pred_inter_1 <- rep("Dow",length(prediction_inter_1))
pred_inter_1[prediction_inter_1 > 0.5] <- "Up"


mod_lda_inter <-lda(Direction~Lag2:Lag1,data = train)

prediction_LDA_inter <- predict(mod_lda_inter,test2009_2010)


mod_QDA_inter <- qda(Direction ~ Lag2+sqrt(abs(Lag2)),train)
pred_QDA_inter <- predict(mod_QDA_inter,test2009_2010)

set.seed(0511)
#knn k=10
prediction_knn1 <- knn(train = train.x,test = test.x,cl = train.Direction,k = 10)
#knn=100
prediction_knn2 <- knn(train = train.x,test = test.x,cl = train.Direction,k = 100)

```

>**Tablas de modelos realizados con interacciones**

|Modelo|predicción correcta|tasa de presición cuando el mercado aumenta|
|------|-------------------|----------------------------------------|
|regresión logistica con interacción|57.69%|98.36%|
|LDA con interacción| 57.69%|98.36%%|
|QDA con $\sqrt(abs(Lag2))$| 57.69%|78.68%|
|knn con K=10 | 57.69% | 68.85%|
|Knn con k=100| 56.73% | 80.32%|

De esta tabla se puede concluir que el modelo de regresión logística y LDA tienen el mejor rendimiento en tasas de error de prueba.


### Punto 11

*  **En este problema, desarrollará un modelo para predecir si un automóvil determinado obtiene un consumo de combustible alto o bajo en función del conjunto de datos automático.**

**(a) Cree una variable binaria, mpg01, que contenga un 1 si mpg contiene un valor por encima de su mediana, y un 0 si mpg contiene un valor por debajo de su mediana. Puede calcular la mediana utilizando la función median(). Tenga en cuenta que puede resultarle útil utilizar la función data.frame() para crear un único conjunto de datos que contenga tanto mpg01 como las otras variables automáticas.**

```{r}
library(ISLR)
data(Auto)
n <- length(Auto$mpg)

mpg01 <- ifelse( Auto$mpg > median(Auto$mpg),1,0)
Auto <- data.frame(Auto,mpg01)
Auto$mpg01 <- as.factor(Auto$mpg01)

```


```{r,results="asis"}
knitr::kable(head(Auto),caption = "Cabeza de base de datos Auto con variable mpg01")
```


**(b) Explore los datos gráficamente para investigar la asociación entre mpg01 y las otras características. ¿Cuál de las otras características parece más útil para predecir mpg01? Los diagramas de dispersión y los diagramas de caja pueden ser herramientas útiles para responder a esta pregunta. Describe tus hallazgos.**

>Correlaciones entre variables:

```{r}
Auto1 <- Auto
Auto1$mpg01 <- as.numeric(Auto1$mpg01)
cor(Auto1[,-9])
```

> Grafico de dispersion

```{r}
pairs(Auto)
```

```{r}
attach(Auto)
layout(rbind(c(1,1,1,2,2,2,3,3,3),c(4,4,4,5,5,5,6,6,6)))
boxplot(cylinders~mpg01,data = Auto,main="Cilindros vs mpg01")
boxplot(displacement ~mpg01,data = Auto,main="Desplazamiento vs mpg01")
boxplot(horsepower ~mpg01,data = Auto,main="Caballos de fuerza vs mpg01")
boxplot(weight ~mpg01,data = Auto,main="Peso del vehiculo vs mpg01")
boxplot(acceleration ~mpg01,data = Auto,main="Aceleración vs mpg01")
boxplot(year ~mpg01,data = Auto,main="Modelo vs mpg01")



```



**(c) Divida los datos en un conjunto de entrenamiento y un conjunto de prueba.**



```{r}
train <- sample(seq(length(Auto$mpg01)),length(Auto$mpg01)*0.70,replace = FALSE)
data_train <- Auto[train,]
data_test <- Auto[-train,]

```

|Entranamiento|Prueba |Total|
|-------------|-------|-----|
| 274         | 118   | 392 |
|-------------|-------|-----|


**(d)  Realice LDA en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociadas con mpg01 en (b). ¿Cuál es el error de prueba del modelo obtenido?**

```{r}
require(MASS)
fit.lda <- lda(mpg01 ~ cylinders+displacement+horsepower+weight,Auto)
fit.lda
```

```{r}
pred.lda <- predict(fit.lda,data_test)
table(pred.lda$class,data_test$mpg01)
```

```{r}
mean(pred.lda$class != data_test$mpg01)
```
Con los resultados anteriores podemos concluir que la tasa de error es del 11.01%.


**(e) Realice QDA en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociadas con mpg01 en (b). ¿Cuál es el error de prueba del modelo obtenido?**



```{r}
fit.qda <- qda(mpg01~cylinders+displacement+horsepower,data = data_train)
fit.qda
```

```{r}
pred.qda <- predict(fit.qda,data_test)
table(pred.qda$class,data_test$mpg01)

```

```{r}
mean(pred.qda$class != data_test$mpg01)
```
Con los resultados anteriores podemos concluir que la tasa de error es del 11.01%.



**(f) Realice una regresión logística en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociadas con mpg01 en (b). ¿Cuál es el error de prueba del modelo obtenido?**


```{r}
fit.glm <- glm(mpg01 ~ cylinders+displacement+horsepower+weight+acceleration,family = binomial,data_train)
summary(fit.glm)
```
```{r}
pr<- predict(fit.glm,data_test,type = "response")
pred.glm <- rep(0,length(pr))
pred.glm[pr>0.5]<-1
table(pred.glm,data_test$mpg01)
```
```{r}
mean(pred.glm != data_test$mpg01)
```
Con los resultados anteriores podemos concluir que la tasa de error es del 11.86%.



**(g) Realice KNN en los datos de entrenamiento, con varios valores de K, para predecir mpg01. Use solo las variables que parecían más asociadas con mpg01 en (b). ¿Qué errores de prueba obtienes? ¿Qué valor de K parece tener el mejor rendimiento en este conjunto de datos?**

```{r}
require(ggplot2)
require(factoextra)
require(class)
require(caret)
set.seed(0511)
ctrl <- trainControl(method="repeatedcv",repeats = 3) 
knnFit <- train(mpg01 ~ cylinders+displacement+horsepower+weight+acceleration, data =data_train[,-c(1,7,8,9)], method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnFit
```
se obtuvo  un k optimo de 7 procedemos con el modelo.

```{r}
train.x <- as.matrix(data_train[,-c(1,7,8,9)])
test.x <- as.matrix(data_test[,-c(1,7,8,9)])
train.y <- as.matrix(data_train$mpg01)
test.y <- as.matrix(data_test$mpg01)
set.seed(0511)
pred.knn <- knn(train = train.x,test = test.x,cl = train.y,k = 7)
table(pred.knn,test.y)

```
```{r}
mean(pred.knn !=test.y)
```
con los resultados obtenidos con un K=7 optimo la tasa de error es de 13.55%.


**Conclución general**: Los mejores modelos son LDA y QDA con una tasa de error de 11.01%



### Punto 12

*  **Este problema implica escribir funciones.**

**(a) Escriba una función, Power(), que imprima el resultado de elevar 2 a la tercera potencia. En otras palabras, su función debe calcular $2^3$ e imprimir los resultados.Sugerencia: recuerde que $x^a$ eleva x a la potencia a. Use la función print() para generar el resultado.**

```{r}
Power <- function() {
    2^3
}

Power()
```


**(b) Cree una nueva función, Power2(), que le permita pasar dos números, x y a, e imprima el valor de $x^a$. Puede hacer esto comenzando su función con la línea**


```{r}
power <- function(){2^3}
power()
```


**(b) Cree una nueva función, Power2(), que le permita pasar dos números, x y a, e imprima 
el valor de $x^a$. Puede hacer esto comenzando su función con la línea**


```{r}
Power2 <- function (x,a){x^a}

Power2(3,8)
```



```{r}
Power2 <- function(x, a) {
    x^a
}

Power2(3, 8)
```


**(c) Usando la función Power2() que acaba de escribir, calcule $10^3$, $8^17$ y $131^3$.**


```{r}
Power2(10,3)
```
```{r}
Power2(8,17)
```
```{r}
Power2(131,3)
```






**(d) Ahora cree una nueva función, Power3(), que realmente devuelve el resultado x^a como un objeto R, en lugar de simplemente imprimirlo en la pantalla. Es decir, si almacena el valor x^a en un objeto llamado resultado dentro de su función, simplemente puede return() este resultado, utilizando la siguiente línea:**


```{r}
power3 <- function(x,a){
  resultado <- x^a
  return(resultado)
}
```



```{r}
Power3 <- function(x , a) {
    result <- x^a
    return(result)
}
```


**(e) Ahora, utilizando la función Power3 (), cree un plot de f(x) = $x^2$. El eje x debe mostrar un rango de enteros del 1 al 10, y el eje y debería mostrar $x^2$. Rotule los ejes apropiadamente y use un título apropiado para la figura. Considere mostrar el eje x, el eje y o ambos en la escala logarítmica. Puede hacerlo utilizando log = ‘‘ x ’’, log = ‘‘ y ’’ o log = ‘‘ xy ’’ como argumentos de la función plot()**

>función a graficar:

$$f(x)=x^2$$

```{r}
x <- 1:10
plot(x,power3(x,2),log = "xy",xlab = "log de x",ylab = "log de x^2",main = "log de x^2 vs log de x")
```


```{r}
x <- 1:10
plot(x, Power3(x, 2), log = "xy", xlab = "Log of x", ylab = "Log of x^2", main = "Log of x^2 vs Log of x")
```


**(f) Cree una función, PlotPower (), que le permite crear una gráfica de x contra x ^ a para un a fijo y para un rango de valores de x. Por ejemplo, si llamas**



**entonces se debe crear un gráfico con un eje x que tome valores 1,2, ..., 10 y un eje y que toma los valores $1^3$,$2^3$, ..., $10^3$.**


```{r}
plotpower <- function(x,a){
  plot(x,power3(x,a))
}
plotpower(1:10,3)
```


```{r}
PlotPower <- function(x, a) {
    plot(x, Power3(x, a))
}

PlotPower(1:10, 3)
```


### Punto 13

**Utilizando el conjunto de datos de Boston, ajuste los modelos de clasificación para predecir si un suburbio determinado tiene una tasa de criminalidad superior o inferior a la mediana. Explore los modelos de regresión logística, LDA y KNN utilizando varios subconjuntos de predictores. Describe tus hallazgos.**

```{r}
library(MASS)
data("Boston")
medianacrim <- median(Boston$crim)
crim01 <- rep(0,length(Boston$crim))
crim01[Boston[1]>medianacrim] <- 1
Boston$crim01 <- crim01
train <- sample(seq(length(Boston$crim01)),length(Boston$crim01)*0.70,replace = FALSE)
data_train <- Boston[train,]
data_test <- Boston[-train,]

```


>Regresion logistica:

```{r}

fit.glm <- glm(crim01~zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat,family = binomial,data_train)
summary(fit.glm)
```
```{r}
prob.glm <- predict(fit.glm,data_test,type = "response")
pred.glm <- rep(0,length(prob.glm))
pred.glm[prob.glm > 0.5] <- 1
table(pred.glm,data_test$crim01)
```

```{r}
mean(pred.glm != data_test$crim01)
```

con los resultados obtenidos la tasa de error es de 13.15% 

Con variables predictora con correlacion fuerte
```{r}
fit.glm1 <- glm(crim01~indus+nox+age+dis+rad+tax+black+lstat,family = binomial,data_train)
summary(fit.glm1)
```
```{r}
prob.glm1 <- predict(fit.glm1,data_test,type = "response")
pred.glm1 <- rep(0,length(prob.glm1))
pred.glm1[prob.glm1 > 0.5] <- 1
table(pred.glm1,data_test$crim01)

```

```{r}
mean(pred.glm1 != data_test$crim01)
```
con estos variables predictoras la tasa de error es de 15.13%.


>LDA:

```{r}
fit.lda <- lda(crim01~zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat , data = data_train)
fit.lda
```

```{r}
pred.lda <- predict(fit.lda,data_test)
table(pred.lda$class,data_test$crim01)

```

```{r}
mean(pred.lda$class != data_test$crim01)
```
Con los resultados obtenidos con este metodo, la tasa de error es de 17.10% mas que la regresión logistíca.

Ahora con las variables predictoras con correlación fuerte.
```{r}
fit.lda1 <- lda(crim01~indus+nox+age+dis+rad+tax+black+lstat , data = data_train)
fit.lda1

```

```{r}
pred.lda <- predict(fit.lda,data_test)
table(pred.lda$class,data_test$crim01)

```

```{r}
mean(pred.lda$class != data_test$crim01)
```
Con estas covariables se obtiene una tasa de error de 17.10% igual que la anterior pero por pricipio de parcimonia es mejor este modelo con pocas variables



>KNN

```{r}
set.seed(0511)
data_train$crim01 <- as.factor(data_train$crim01)
ctrl <- trainControl(method="repeatedcv",repeats = 3) 
knnFit <- train(crim01~zn+indus+chas+nox+rm+age+dis+rad+tax+ptratio+black+lstat, data =data_train, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnFit
```
Un K optimo para este metodo de clasificación es 5.


```{r}
train.x <- as.matrix(data_train[,-c(1,14)])
test.x <- as.matrix(data_test[,-c(1,14)])
train.y <- as.matrix(data_train$crim01)
test.y <- as.matrix(data_test$crim01)
set.seed(0511)
pred.knn <- knn(train = train.x , test = test.x,cl = train.y,k=5)
table(pred.knn,test.y)
```

```{r}
mean(pred.knn !=test.y)
```

Este metodo tiene una tasa de error de 7.2% mucho mejor que los anteriores.





## Capitulo VIII {.tabset .tabset-fade .tabset-pills}

### Punto 7

*  **En el laboratorio, aplicamos bosques aleatorios a los datos de Boston usando mtry = 6 y usando ntree = 25 y ntree = 500. Cree un gráfico que muestre el error de prueba resultante de bosques aleatorios en este conjunto de datos para un rango de valores más amplio para mtry y ntree. Puede modelar su diagrama después de la Figura 8.10. Describa los resultados obtenidos.**

```{r}
library(MASS)
library(randomForest)
train <- sample(1:nrow(Boston),length(Boston$crim)*0.70,replace = FALSE)
data.train <- Boston[train,-14]
data.test <- Boston[-train,-14]
y.train <- Boston[train,14]
y.test <- Boston[-train,14]
set.seed(0511)
boston.1 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = ncol(Boston)-1)

boston.2 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = (ncol(Boston)-1)/2)

boston.3 <- randomForest(x = data.train,y = y.train,xtest = data.test,ytest = y.test,
                         ntree = 500,mtry = sqrt(ncol(Boston)-1))

val <- data.frame(arboles = 1:500)
val["MSE1"] <- boston.1$test$mse
val["MSE2"] <- boston.2$test$mse
val["MSE3"] <- boston.3$test$mse

library(ggplot2)
library(reshape2)
xy <- melt(val,id=c("arboles"))

theme_set(theme_bw())
ggplot(xy)+geom_line(aes(x=arboles,y = value,color=variable))+
  scale_color_manual(name=" m = ",labels=c("p","p/2","\u221Ap"),values = c("orange","red","green"))+labs(x = "Número de árboles",
       y = "Error de clasificación") +
  theme(legend.position="top")


```

Con esta grafica podemos observar que la prueba MSE es muy alta para un solo arbol, a mededida que aunmenta los arboles el error se estabiliza aproximademente cuando hay 150 arboles, La estaibilización se presenta para los tres valores de "m". El m que menor reprensenta error es m = $sqrt(p)$.Ojo que al variar la semilla se podra concluir diferente.


### Punto 8


*  **En el laboratorio, se aplicó un árbol de clasificación al conjunto de datos de Carseats después de convertir las ventas en una variable de respuesta cualitativa. Ahora buscaremos predecir las ventas utilizando árboles de regresión y enfoques relacionados, tratando la respuesta como una variable cuantitativa.**

**(a) Divida el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.**

```{r}
library(ISLR)
set.seed(0511)
train <- sample(1:nrow(Carseats),nrow(Carseats)*0.65,replace = FALSE)
carseats.train <- Carseats[train,]
carseats.test <- Carseats[-train,]

```


**(b) Ajuste un árbol de regresión al conjunto de entrenamiento. Trace el árbol e interprete los resultados. ¿Qué prueba MSE obtienes?**

```{r}

library(rpart)
library(rpart.plot)
carseats.tree <- rpart(Sales~.,data = carseats.train)
rpart.plot(carseats.tree,box.palette = "RdBu",nn=TRUE)


```

```{r}
pred <- predict(carseats.tree,carseats.test)
mean((pred - carseats.test$Sales)^2)


```
con el anterior resultado concluimos que el MSE es aproximadamente de 5.46.


**(c) Utilice la validación cruzada para determinar el nivel óptimo de complejidad del árbol. ¿La poda del árbol mejora la prueba MSE?**



```{r}
printcp(carseats.tree)
```
```{r}
plotcp(carseats.tree)
```
```{r}
min <- which.min(carseats.tree$cptable[,"xerror"])
print(min)

```
```{r}
cpt <- carseats.tree$cptable[which.min(carseats.tree$cptable[,"xerror"]),"CP"]
cpt
```
con la validación cruzada obtenemos un tamaño de arbol igual a 13 y un cp de 0.01357961

```{r}
ptree <- prune(carseats.tree,cp = cpt)
rpart.plot(ptree,box.palette = "RdBu",nn=TRUE)
```

```{r}
pred1 <- predict(ptree,newdata = carseats.test)
m2 <- mean((pred1-carseats.test$Sales)^2)
m2
```
Se disminuye  el MSE despues de que se poda.


**(d) Utilice el enfoque de embolsado para analizar estos datos. ¿Qué prueba MSE obtienes? Use la función importance() para determinar qué variables son más importantes.**


```{r}
bag.carseats <- randomForest(Sales~.,carseats.train,mtry=(ncol(Carseats)-1) ,importance=TRUE)
pred2 <- predict(bag.carseats,newdata = carseats.test)
mean((pred2- carseats.test$Sales)^2)
```
notablemente mejora el MSE a 3.37627.


```{r}
importance(bag.carseats)
```
Se puede concluir con lo anterior que Price,Shelveloc,CompPrice son variables importantes para este analisis.

**(e) Utilice bosques aleatorios para analizar estos datos. ¿Qué prueba MSE obtienes? Use la función importance() para determinar qué variables son las más importantes. Describa el efecto de m, el número de variables consideradas en cada división, sobre la tasa de error obtenida.**


```{r}
bag.carseats <- randomForest(Sales ~ ., data = carseats.train, mtry = sqrt((ncol(Carseats) - 1)), importance = TRUE)
pred.bag <- predict(bag.carseats, newdata = carseats.test)
mean((pred.bag - carseats.test$Sales)^2)
```
Con lo anterior tenemos un MSE de 3.38
```{r}
importance(bag.carseats)
```
Con lo anterior cuncluimos que las mejores varibales predictoras para el analisis son las mismas que el numeral anterior.


### Punto 9

* **Este problema involucra el conjunto de datos de OJ que es parte del paquete ISLR.**

**(a) Cree un conjunto de entrenamiento que contenga una muestra aleatoria de 800 observaciones, y un conjunto de prueba que contenga las observaciones restantes.**
```{r}
train <- sample(x = 1:nrow(OJ),size = 800)
OJ.train <- OJ[train,]
OJ.test <- OJ[-train,]

```



**(b) Ajuste un árbol a los datos de entrenamiento, con Compra como respuesta y las otras variables como predictores. Use la función summary() para generar estadísticas resumidas sobre el árbol y describa los resultados obtenidos. ¿Cuál es la tasa de error de entrenamiento? ¿Cuántos nodos terminales tiene el árbol?**


```{r}
set.seed(0511)
library(tree)
tree.oj <- tree(Purchase~.,data = OJ.train)
summary(tree.oj)

```
Este arbalo tiene 8 nodos terminales y una tasa de error de entrenamiento de 0.1612


**(c) Escriba el nombre del objeto del árbol para obtener una salida de texto detallada. Elija uno de los nodos terminales e interprete la información que se muestra.**

```{r}
tree.oj
```
Escogemos el nodo terminal 15, debido a que es un nodo terminal debido al asterisco.apreciamos que su criterio de división es LoyalCH > 0.764572 esta tiene 254 observaciones en este nodo y una desviación estandar 64.090. La predicción general para la rama CH,también podemos ver que el 97.24% de las observaciones toman el valor de CH, mientras que el 0.02756 tomal el valor de MM.

**(d) Cree un diagrama del árbol e interprete los resultados.**

```{r}

plot(tree.oj)
text(tree.oj, pretty = 0)
```
Podemos apreciar que el nodo principal es LoyalCH si es menor o igual a 0.50 solo usa a su misma variables , pero si es menor utiliza a PriceDiff.


**(e) Predecir la respuesta en los datos de prueba, y producir una matriz de confusión comparando las etiquetas de prueba con las etiquetas de prueba predichas. ¿Cuál es la tasa de error de prueba?**


```{r}
library(caret)
tree.pred <- predict(tree.oj, OJ.test, type = "class")

matrix<-confusionMatrix(tree.pred, OJ.test$Purchase)
matrix
```
Observamos que la precisión del modelo es de 82.89%, siendo mas preciso para predecir a CH con un 90.65% mientras que para predecir MM sólo es de un 70.91%.
**(f) Aplique la función cv.tree() al conjunto de entrenamiento para determinar el tamaño óptimo del árbol.**

```{r}
cv.oj <- cv.tree(tree.oj,FUN = prune.misclass)
cv.oj
```


**(g) Produzca un diagrama con el tamaño del árbol en el eje xy la tasa de error de clasificación con validación cruzada en el eje y.**

```{r}
library(ggplot2)
library(reshape2)
valores <- data.frame(Size=cv.oj$size,Dev=cv.oj$dev)
theme_set(theme_bw())
ggplot(data = valores, aes(x=Size, y=Dev)) + 
  geom_line(color="red", linetype = "dashed") +
  geom_point() +
  scale_x_discrete(limits=c(1:9))

```



**(h) ¿Qué tamaño de árbol corresponde a la tasa de error de clasificación con validación cruzada más baja?**
 5 es el tamaño con menor error 

**(i) Produzca un árbol podado correspondiente al tamaño óptimo del árbol obtenido mediante validación cruzada. Si la validación cruzada no conduce a la selección de un árbol podado, cree un árbol podado con cinco nodos terminales.**


```{r}
prune.oj <- prune.misclass(tree.oj,best = 5)
plot(prune.oj)
text(prune.oj,pretty = 0)
```

**(j) Compare las tasas de error de entrenamiento entre los árboles podados y no podados. ¿Cuál es más alto?**

```{r}
summary(prune.oj)
```

```{r}
summary(tree.oj)
```
observamos que hay una diferencia en el erro mayor el arbol podado. 
**(k) Compare las tasas de error de prueba entre los árboles podados y no podados. ¿Cuál es más alto?**

```{r}
prune.pred <- predict(prune.oj, OJ.test, type = "class")

matrix<-confusionMatrix(prune.pred, OJ.test$Purchase)
matrix
```
observamos que bajo la presicion del modelo notablemente con respecto al árbol sin podar.


### Punto 10

* **Ahora usamos el aumento para predecir el salario en el conjunto de datos de Hitters.**

**(a) Elimine las observaciones para las que se desconoce la información salarial, y luego transforme logarítmicamente los salarios.**


```{r}
Hitters <- na.omit(Hitters)
Hitters$Salary <- log(Hitters$Salary)

```

**(b) Cree un conjunto de entrenamiento que consista en las primeras 200 observaciones, y un conjunto de prueba que consista en las observaciones restantes.**

```{r}
train <- 1:200
Hitters.train <- Hitters[train,]
Hitters.test <- Hitters[-train,]
```


**(c) Realice un refuerzo en el conjunto de entrenamiento con 1,000 árboles para un rango de valores del parámetro de contracción $\lambda$. Produzca un gráfico con diferentes valores de contracción en el eje xy el conjunto de entrenamiento MSE correspondiente en el eje y.**


```{r}
library(gbm)
set.seed(0511)
lambdas = seq(0.001, 0.3, 0.005)
mse <- rep(0, length(lambdas))
for (i in 1:length(lambdas)) {
  boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
    pred.train <- predict(boost.hitters, Hitters.train, n.trees = 1000)
    mse[i] <- mean((pred.train - Hitters.train$Salary)^2)
}
```
```{r}
library(ggplot2)

mse_graph <- data.frame(lambdas)
mse_graph["MSE"]<- mse
names(mse_graph) <- c("Lambdas", "MSE")

theme_set(theme_bw()) 
ggplot(data = mse_graph, aes(x = Lambdas, y = MSE)) +
  geom_line(color="red", linetype = "dashed") +
  geom_point() 
```


**(d) Produzca un gráfico con diferentes valores de contracción en el eje xy el conjunto de prueba MSE correspondiente en el eje y.**

```{r}
mse2 <- rep(NA, length(lambdas))
for (i in 1:length(lambdas)) {
    boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[i])
    yhat <- predict(boost.hitters, Hitters.test, n.trees = 1000)
    mse2[i] <- mean((yhat - Hitters.test$Salary)^2)
}
```

```{r}
library(ggplot2)

mse_graph2 <- data.frame(lambdas)
mse_graph2["MSE"]<- mse2
names(mse_graph2) <- c("Lambdas", "MSE")

theme_set(theme_bw()) 
ggplot(data = mse_graph2, aes(x = Lambdas, y = MSE)) +
  geom_line(color="red", linetype = "dashed") +
  geom_point() 
```

```{r}
min(mse2)
```
```{r}
lambdas[which.min(mse2)]
```


**(e) Compare la prueba MSE de refuerzo con la prueba MSE que resulta de aplicar dos de los enfoques de regresión vistos en los Capítulos 3 y 6.**


```{r}
mod8.10 <- lm(Salary~.,data = Hitters.train)
pred8.10 <- predict(mod8.10,Hitters.test)
mean((pred8.10-Hitters.test$Salary)^2)
```

```{r}

library(pls)
pcr.fit=pcr(Salary~., data=Hitters.train , scale=TRUE , validation ="CV")
validationplot(pcr.fit ,val.type="MSEP")

```

```{r}
pcr.pred=predict (pcr.fit ,Hitters.test,ncomp =1)
mean((pcr.pred -Hitters.test$Salary)^2)
```
observamos que el MSE de la regresion lineal y de las componentes principales es mayor el MSE por el metodo Boosting 

**(f) ¿Qué variables parecen ser los predictores más importantes en el modelo impulsado?**
```{r}
boost.hitters <- gbm(Salary ~ ., data = Hitters.train, distribution = "gaussian", n.trees = 1000, shrinkage = lambdas[which.min(mse2)])
summary(boost.hitters)
```
En la tabla se observa que la variable mas importante es CatBat.

**(g) Ahora aplique el embolsado al conjunto de entrenamiento. ¿Cuál es el conjunto de prueba MSE para este enfoque?**


```{r}
bag.hitters <- randomForest(Salary ~ ., data = Hitters.train, mtry = 19)
yhat.bag <- predict(bag.hitters, newdata = Hitters.test)
mean((yhat.bag - Hitters.test$Salary)^2)
```
El MSE es de 0.2339 es mucho mejor que los otros metodos por el momento.
### Punto 11

* **Esta pregunta utiliza el conjunto de datos de Caravan.**

**(a) Cree un conjunto de entrenamiento que consista en las primeras 1,000 observaciones,y un conjunto de prueba que consta de las observaciones restantes.**


```{r}
library(ISLR)
data(Caravan)
set.seed(1)
train <- 1:1000
Caravan$Purchase <- ifelse(Caravan$Purchase=="Yes",1,0)

Caravan.train <- Caravan[train,]
Caravan.test <- Caravan[-train,]

```


**(b) Ajuste un modelo de refuerzo al conjunto de entrenamiento con Compra como respuesta y las otras variables como predictores. Use 1,000 árboles y un valor de contracción de 0.01. ¿Qué predictores parecen ser los más importantes?**

```{r}
set.seed(0511)
library(gbm)
boost.caravan <- gbm(Purchase~.,data = Caravan.train,distribution = "gaussian",
                     n.trees = 1000,shrinkage = 0.01)

summary(boost.caravan)
```
En la tabla observamos PPERSAUT y MKOOPKLA son las mas importantes.

**(c) Utilice el modelo de refuerzo para predecir la respuesta en los datos de la prueba. Predecir que una persona realizará una compra si la probabilidad estimada de compra es superior al 20%. Forme una matriz de confusión. ¿Qué fracción de las personas que predijeron hacer una compra en realidad la hacen? ¿Cómo se compara esto con los resultados obtenidos al aplicar KNN o regresión logística a este conjunto de datos?**

<<<<<<< HEAD
```{r}
library(caret)
probs.test <- predict(boost.caravan,Caravan.test,n.trees = 1000,type = "response")

predict.test <- ifelse( probs.test > 0.2, 1 , 0)
matrixx <- confusionMatrix(as.factor(predict.test),as.factor(Caravan.test$Purchase))
matrixx
```

Observamos que la personas que en realidad harán una compra la predicción tiene un precisión del 4.15%

```{r}
logit.caravan <- glm(Purchase ~ ., data = Caravan.train, family = "binomial")
```
```{r}
probs.test2 <- predict(logit.caravan,Caravan.test,type = "response")
pred.test2 <- ifelse(probs.test > 0.2, 1, 0)
matriz <- confusionMatrix(as.factor(pred.test2), as.factor(Caravan.test$Purchase))
matriz
```
Utilizando la regresion logística para predecir las personas que realmente hicieron una compra tiene un apresición de 4.1%.

###Punto 12
=======
### Punto 12
>>>>>>> a01ebbb180b6a06ed78bd1e25d2506e6477d16ab

* **Aplique impulso, embolsado y bosques aleatorios a un conjunto de datos de su elección. Asegúrese de ajustar los modelos en un conjunto de entrenamiento y evaluar su desempeño en un conjunto de prueba. ¿Cuán precisos son los resultados en comparación con métodos simples como la regresión lineal o logística? ¿Cuál de estos enfoques produce el mejor rendimiento?**


Uitilizando una base de datos de niños deportistas en Antiquia del 2018 de morfologia. Con esta base de intentara clasificar el peso en kg por ensima y por debajo de la mediana.

```{r}
Morfo <- read.csv2("C:/Users/jupja/Desktop/UN/TAE/Taller-TAE-2019-2.github.io/Morfologia_ninos_ANT.csv",sep = ";")
Morfo <- Morfo[,-1]
Morfo <- na.omit(Morfo)
peso01 <- rep(0,length(Morfo$Peso.kg.))
peso01[Morfo$Peso.kg. > median(Morfo$Peso.kg.)]<-1
Morfo$peso01 <- peso01
Morfo <- Morfo[,-1]
train <- sample(1:nrow(Morfo),length(Morfo$peso01)*0.70,replace = FALSE)
Morfo.train <- Morfo[train,]
Morfo.test <- Morfo[-train,]

```

>Aplicando Boosting

```{r}
set.seed(0511)
bf <- gbm(peso01~.,Morfo.train,distribution = "bernoulli",n.trees = 5000)
bprobs  <- predict(bf,newdata = Morfo.test,n.trees = 5000)
bpredic <- ifelse(bprobs >0.5,1,0)
table(bpredic,Morfo.test$peso01)
```
Podemos concluir con lo anterior que este modelo puede clasificar un 96.62% de la veces el peso de los niños por encima y por debajo de la mediana.

>regresión logistica

```{r}
logit.mor <- glm(peso01~.,data = Morfo.train,family = "binomial")
logit.probs <- predict(logit.mor,newdata = Morfo.test,type = "response")
logit.pred <- ifelse(logit.probs >0.5 ,1,0)
table(logit.pred,Morfo.test$peso01)
```
Tenemos un error de clasifación de 3.83%. 

>bosques aleatorios

```{r}
library(randomForest)

forest.morfo <- randomForest(peso01~.,data = Morfo.test,mtry=5)
for.probs <- predict(forest.morfo,newdata = Morfo.test)
for.predic <- ifelse(for.probs >0.5,1,0)
matrixx <- confusionMatrix(as.factor(for.predic),as.factor(Morfo.test$peso01))
matrixx
```
Concluimos que el error de predicción 0.09% para clasificar los pesos por encima y por debajo de la mediana.

>regresión lineal.

```{r}
lm.morf <- lm(peso01~.,Morfo.train)
probs.morf <- predict(lm.morf,Morfo.test)  
predic.morf <- ifelse(probs.morf>0.5,1,0)
matrixx <- confusionMatrix(as.factor(predic.morf),as.factor(Morfo.test$peso01))
matrixx
```
Observamos que el modelo tiene un error de predicción de 6.02%.


**Conclusión:** El mejor modelo para la predicción son los bosques aleatorios con un error de 0.09% a comparación de los demas. 
 
## Capitulo IX {.tabset .tabset-fade .tabset-pills}

### Punto 4

* **Genere un conjunto de datos simulados de dos clases con 100 observaciones y dos características en las que haya una separación visible pero no lineal entre las dos clases. Muestre que en esta configuración, una máquina de vectores de soporte con un núcleo polinomial (con un grado mayor que 1) o un núcleo radial superará a un clasificador de vectores de soporte en los datos de entrenamiento. ¿Qué técnica funciona mejor en los datos de prueba? Haga tramas e informe la capacitación y pruebe las tasas de error para respaldar sus afirmaciones.**

```{r}
library(e1071)
set.seed(1)
x <- rnorm(100)
y <- 4 * x^3 + 1 + rnorm(100)
class <- sample(100, 50)
y[class] <- y[class] + 3
y[-class] <- y[-class] - 3
plot(x[class], y[class], col = "green", xlab = "X", ylab = "Y", ylim = c(-10, 25), xlim = c(-1.5, 2.0))
points(x[-class], y[-class], col = "blue")
```

#### Clasificador de soporte en los datos de entrenamiento

```{r}
z <- rep(-1, 100)
z[class] <- 1
data <- data.frame(x = x, y = y, z = as.factor(z))
train <- sample(100, 50)
data.train <- data[train, ]
data.test <- data[-train, ]
svm.linear <- svm(z ~ ., data = data.train, kernel = "linear", cost = 10)
plot(svm.linear, data.train)
```

```{r}
table(predict = predict(svm.linear, data.train), truth = data.train$z)
```

#### El clasificador de vectores de soporte comete 4 errores en los datos de entrenamiento.

#### Maquina de vectores de soporte con un núcleo polinomial.



```{r}
svm.poly <- svm(z ~ ., data = data.train, kernel = "polynomial", cost = 10)
plot(svm.poly, data.train)
```


```{r}
table(predict = predict(svm.poly, data.train), truth = data.train$z)
```

#### La máquina de vectores de soporte comete 2 errores en los datos de entrenamiento.

```{r}
svm.radial <- svm(z ~ ., data = data.train, kernel = "radial", gamma = 1, cost = 10)
plot(svm.radial, data.train)
```

```{r}
table(predict = predict(svm.radial, data.train), truth = data.train$z)
```

#### La máquina con un núcleo radial comete  0  errores en los datos de entrenamiento.

#### Aplicando a los datos de prueba.

```{r}
plot(svm.linear, data.test)
```

```{r}
table(predict = predict(svm.linear, data.test), truth = data.test$z)
```
```{r}
plot(svm.poly, data.test)
```

```{r}
table(predict = predict(svm.poly, data.test), truth = data.test$z)
```

```{r}
plot(svm.radial, data.test)
```

```{r}
table(predict = predict(svm.radial, data.test), truth = data.test$z)
```

#### Como vemos en los resultados anteriores, las máquinas de vectores de soporte lineal, polinomial y radial clasifican, respectivamente 4, 2 y 0 observaciones de forma incorrecta. Entonces, el núcleo radial es el mejor modelo en este caso.

### Punto 5

* **Hemos visto que podemos ajustar un SVM con un núcleo no lineal para realizar la clasificación utilizando un límite de decisión no lineal. Ahora veremos que también podemos obtener un límite de decisión no lineal al realizar una regresión logística utilizando transformaciones no lineales de las características.**


**(a) Genere un conjunto de datos con n = 500 y p = 2, de modo que las observaciones pertenezcan a dos clases con un límite de decisión cuadrático entre ellas. Por ejemplo, puede hacer esto de la siguiente manera:**

**> x1 = runif (500) -0.5**

**> x2 = runif (500) -0.5**

**> y = 1 * (x1 ^ 2-x2 ^ 2> 0)**

```{r}
set.seed(1)
x1 <- runif(500) - 0.5
x2 <- runif(500) - 0.5
y <- 1 * (x1^2 - x2^2 > 0)
```


**(b) Grafique las observaciones, coloreadas de acuerdo con sus etiquetas de clase. Su diagrama debe mostrar X1 en el eje xy X2 en el eje y.**

```{r}
plot(x1, x2, xlab = "X1", ylab = "X2", col = (5 - y), pch = (2 - y))
```


**(c) Ajuste un modelo de regresión logística a los datos, utilizando X1 y X2 como predictores.**

```{r}
logit.fit <- glm(y ~ x1 + x2, family = "binomial")
summary(logit.fit)
```

#### Ninguna de las variables es estadísticamente significativa.

**(d) Aplique este modelo a los datos de entrenamiento para obtener una etiqueta de clase predicha para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas. El límite de decisión debe ser lineal.**

```{r}
data <- data.frame(x1 = x1, x2 = x2, y = y)
probs <- predict(logit.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (6 - 1), pch = (2 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (2 - 0))
```

#### El límite de decisión es lineal.

**(e) Ahora ajuste un modelo de regresión logística a los datos utilizando funciones no lineales de X1 y X2 como predictores (por ejemplo, X12, X1 × X2, log (X2), etc.).**

```{r}
logitnl.fit <- glm(y ~ poly(x1, 2) + poly(x2, 2) + I(x1 * x2), family = "binomial")
```

```{r}
summary(logitnl.fit)
```

#### De nuevo ninguna de las variables son estadisticamente significativas


**(f) Aplique este modelo a los datos de entrenamiento para obtener una etiqueta de clase predicha para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas. El límite de decisión debe ser obviamente no lineal. Si no es así, repita (a) - (e) hasta que encuentre un ejemplo en el que las etiquetas de clase predichas sean obviamente no lineales.**

```{r}
probs <- predict(logitnl.fit, data, type = "response")
preds <- rep(0, 500)
preds[probs > 0.47] <- 1
plot(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (6 - 1), pch = (2 - 1), xlab = "X1", ylab = "X2")
points(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (4 - 0), pch = (2 - 0))
```

#### El límite de decisión no lineal es muy similar al límite de decisión real.


**(g) Ajuste un clasificador de vector de soporte a los datos con X1 y X2 como predictores. Obtenga una predicción de clase para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas.**

```{r}
data$y <- as.factor(data$y)
svm.fit <- svm(y ~ x1 + x2, data, kernel = "linear", cost = 0.01)
preds <- predict(svm.fit, data)
plot(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (5 - 0), pch = (2 - 0), xlab = "X1", ylab = "X2")
points(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (4 - 1), pch = (2 - 1))
```

#### Este clasificador de vectores de soporte clasifica todos los puntos en una sola clase.

**(h) Ajuste un SVM usando un núcleo no lineal a los datos. Obtenga una predicción de clase para cada observación de entrenamiento. Trace las observaciones, coloreadas de acuerdo con las etiquetas de clase predichas.**

```{r}
data$y <- as.factor(data$y)
svmnl.fit <- svm(y ~ x1 + x2, data, kernel = "radial", gamma = 1)
preds <- predict(svmnl.fit, data)
plot(data[preds == 0, ]$x1, data[preds == 0, ]$x2, col = (5 - 0), pch = (1 - 0), xlab = "X1", ylab = "X2")
points(data[preds == 1, ]$x1, data[preds == 1, ]$x2, col = (5 - 1), pch = (2 - 1))
```

#### De nuevo el límite de decisión no lineal es muy similar al límite de decisión verdadero.

**(i) Comente sus resultados.**

#### Con los anteriores resultados podemos concluir que las maquinas de soporte con metodos no lineal y regresión logística con términos de interacción son muy efectivas. 

### Punto 6

* **Al final de la Sección 9.6.1, se afirma que, en el caso de los datos que son apenas linealmente separables, un clasificador de vectores de soporte con un pequeño valor de costo que clasifica erróneamente un par de observaciones de entrenamiento puede funcionar mejor en los datos de prueba que uno con un enorme valor de costo que no clasifica erróneamente ninguna observación de capacitación. Ahora investigará este reclamo.**

**(a) Genere datos de dos clases con p = 2 de tal manera que las clases sean apenas separables linealmente.**

```{r}
set.seed(1)
x.one <- runif(500, 0, 90)
y.one <- runif(500, x.one + 10, 100)
x.one.noise <- runif(50, 20, 80)
y.one.noise <- 5/4 * (x.one.noise - 10) + 0.1

x.zero <- runif(500, 10, 100)
y.zero <- runif(500, 0, x.zero - 10)
x.zero.noise <- runif(50, 20, 80)
y.zero.noise <- 5/4 * (x.zero.noise - 10) - 0.1

class.one <- seq(1, 550)
x <- c(x.one, x.one.noise, x.zero, x.zero.noise)
y <- c(y.one, y.one.noise, y.zero, y.zero.noise)

plot(x[class.one], y[class.one], col = "blue", pch = 5, ylim = c(0, 100))
points(x[-class.one], y[-class.one], col = "lightblue", pch = 5)
```


**(b) Calcule las tasas de error de validación cruzada para los clasificadores de vectores de soporte con un rango de valores de costo. ¿Cuántos errores de capacitación están mal clasificados para cada valor de costo considerado, y cómo se relaciona esto con los errores de validación cruzada obtenidos?**

```{r}
set.seed(2)
z <- rep(0, 1100)
z[class.one] <- 1
data <- data.frame(x = x, y = y, z = as.factor(z))
tune.out <- tune(svm, z ~ ., data = data, kernel = "linear", ranges = list(cost = c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)))
summary(tune.out)
```
```{r}
data.frame(cost = tune.out$performance$cost, misclass = tune.out$performance$error * 1100)
```


**(c) Genere un conjunto de datos de prueba apropiado y calcule los errores de prueba correspondientes a cada uno de los valores de costo considerados. ¿Qué valor del costo conduce a la menor cantidad de errores de prueba, y cómo se compara esto con los valores de costo que producen la menor cantidad de errores de capacitación y la menor cantidad de errores de validación cruzada?**

```{r}
x.test <- runif(1000, 0, 100)
class.one <- sample(1000, 500)
y.test <- rep(NA, 1000)
# Set y > x for class.one
for (i in class.one) {
    y.test[i] <- runif(1, x.test[i], 100)
}
# set y < x for class.zero
for (i in setdiff(1:1000, class.one)) {
    y.test[i] <- runif(1, 0, x.test[i])
}
plot(x.test[class.one], y.test[class.one], col = "blue", pch = 5)
points(x.test[-class.one], y.test[-class.one], col = "lightblue", pch = 5)

```
```{r}
set.seed(3)
z.test <- rep(0, 1000)
z.test[class.one] <- 1
data.test <- data.frame(x = x.test, y = y.test, z = as.factor(z.test))
costs <- c(0.01, 0.1, 1, 5, 10, 100, 1000, 10000)
test.err <- rep(NA, length(costs))
for (i in 1:length(costs)) {
    svm.fit <- svm(z ~ ., data = data, kernel = "linear", cost = costs[i])
    pred <- predict(svm.fit, data.test)
    test.err[i] <- sum(pred != data.test$z)
}
data.frame(cost = costs, misclass = test.err)
```


**(d) Discuta sus resultados.**

### Punto 7

* **En este problema, utilizará enfoques de vectores de soporte para predecir si un automóvil determinado obtiene un millaje de gasolina alto o bajo en función del conjunto de datos automático.**

**(a) Cree una variable binaria que tome un 1 para los automóviles con millaje de gasolina por encima de la mediana, y un 0 para automóviles con millaje de gasolina por debajo de la mediana.**


**(b) Ajuste un clasificador de vector de soporte a los datos con varios valores de costo, para predecir si un automóvil obtiene un millaje de gasolina alto o bajo. Informe los errores de validación cruzada asociados con diferentes valores de este parámetro. Comenta tus resultados.**


**(c) Ahora repita (b), esta vez usando SVM con núcleos de base radial y polinomial, con diferentes valores de gamma y grado y costo. Comenta tus resultados.**

**(d) Haga algunos gráficos para respaldar sus afirmaciones en (b) y (c). Sugerencia: En el laboratorio, utilizamos la función plot() para objetos svm solo en casos con p = 2. Cuando p> 2, puede usar la función plot() para crear gráficos que muestren pares de variables a la vez. Esencialmente, en lugar de escribir**

**> plot (svmfit, dat)**

**donde svmfit contiene su modelo ajustado y dat es un marco de datos que contiene sus datos, puede escribir**

**> plot (svmfit, dat, x1∼x4)**

**para graficar solo las variables primera y cuarta. Sin embargo, debe reemplazar x1 y x4 con los nombres correctos de las variables. Para obtener más información, escriba ?Plot.svm.**

### Punto 8


* **Este problema involucra el conjunto de datos de OJ que es parte del paquete ISLR.**

**(a) Cree un conjunto de entrenamiento que contenga una muestra aleatoria de 800 observaciones, y un conjunto de prueba que contenga las observaciones restantes.**

**(b) Ajuste un clasificador de vector de soporte a los datos de entrenamiento usando cost = 0.01, con Compra como respuesta y las otras variables como predictores. Use la función summary() para generar estadísticas resumidas y describir los resultados obtenidos.**

**(c) ¿Cuáles son las tasas de error de capacitación y prueba?**

**(d) Use la función tune() para seleccionar un costo óptimo. Considere values en el rango de 0.01 a 10.**

**(e) Calcule las tasas de error de entrenamiento y prueba usando este nuevo valor por el cost**

**(f) Repita las partes (b) a (e) usando una máquina de vectores de soporte con un núcleo radial Use el valor predeterminado para gamma.**

**(g) Repita las partes (b) a (e) usando una máquina de vectores de soporte con un núcleo polinomial Establecer grado = 2.**

**(h) En general, ¿qué enfoque parece dar los mejores resultados con estos datos?**

